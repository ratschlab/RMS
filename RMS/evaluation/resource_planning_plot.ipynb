{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0bb08-2367-4753-86fd-c15511abc249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"paper.mplstyle\")\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import utils_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e8993-5bb9-457c-a5e5-0c3738ab4fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = 1/2.54 \n",
    "plot_alpha=0.2\n",
    "h=5.8\n",
    "w=6\n",
    "\n",
    "resp_res_path = \"/cluster/work/grlab/clinical/hirid2/research/event_based_analysis/resp/\"\n",
    "resp_fig_path = \"paper_figures_resp_emer_0\"\n",
    "if not os.path.exists(resp_fig_path):\n",
    "    os.mkdir(resp_fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb0dac-d7b2-41de-883f-37a702422d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(vent_path,\n",
    "                 pred_type, \n",
    "                 horizon_cols, \n",
    "                 param1, \n",
    "                 param2, \n",
    "                 param3, \n",
    "                 metric_bsl, \n",
    "                 metric_lgb, \n",
    "                 lst_seed,\n",
    "                 fill_horizon=10):\n",
    "    df_res = []\n",
    "    for seed in lst_seed:\n",
    "        out_dir = vent_path%seed\n",
    "        for f in os.listdir(out_dir):\n",
    "            if pred_type == \"emergency\":\n",
    "                if \"res_\" in f and \"npz\" in f and \"emer_\" in f:\n",
    "                    tmp = np.load(os.path.join(out_dir, f))\n",
    "                    prediction_horizon_l = int(f.split(\"_\")[3])\n",
    "                    prediction_horizon_r = int(f.split(\"_\")[4])\n",
    "                    num_leaves = int(f.split(\"_\")[5][1:])\n",
    "                    num_rounds = int(f.split(\"_\")[6][1:])\n",
    "                    stopping_rounds = int(f.split(\"_\")[7][1:-4])\n",
    "                    dataset = f.split(\"_\")[2]\n",
    "                    df_res.append( [prediction_horizon_l, \n",
    "                                    prediction_horizon_r, \n",
    "                                    num_leaves, \n",
    "                                    num_rounds, \n",
    "                                    stopping_rounds, \n",
    "                                    dataset, \n",
    "                                    tmp[\"MAE\"], \n",
    "                                    np.mean(np.abs(tmp[\"groundtruth\"]-tmp[\"median_gt_train\"])), \n",
    "                                   ] )\n",
    "            elif pred_type == \"in-icu\":\n",
    "                if \"res_\" in f and \"npz\" in f and \"emer_\" not in f:\n",
    "                    try:\n",
    "                        tmp = np.load(os.path.join(out_dir, f), allow_pickle=True)\n",
    "                    except:\n",
    "                        continue\n",
    "                    prediction_horizon_l = int(f.split(\"_\")[2])\n",
    "                    prediction_horizon_r = int(f.split(\"_\")[3])\n",
    "                    num_leaves = int(f.split(\"_\")[4][1:])\n",
    "                    num_rounds = int(f.split(\"_\")[5][1:])\n",
    "                    stopping_rounds = int(f.split(\"_\")[6][1:-4])\n",
    "                    dataset = f.split(\"_\")[1]\n",
    "                    df_res.append( [prediction_horizon_l, \n",
    "                                    prediction_horizon_r, \n",
    "                                    num_leaves, \n",
    "                                    num_rounds, \n",
    "                                    stopping_rounds, \n",
    "                                    dataset,\n",
    "                                    tmp[\"MAE_RF\"], \n",
    "                                    tmp[\"MAE_baseline\"]\n",
    "                                   ] )\n",
    "\n",
    "    if pred_type == \"emergency\":\n",
    "        df_res = pd.DataFrame(df_res, columns=horizon_cols+\n",
    "                                              [param1, \n",
    "                                               param2, \n",
    "                                               param3, \n",
    "                                               \"Dataset\", \n",
    "                                               metric_lgb,\n",
    "                                               metric_bsl\n",
    "                                              ])\n",
    "    elif pred_type == \"in-icu\":\n",
    "        df_res = pd.DataFrame(df_res, columns=horizon_cols+\n",
    "                                              [param1, \n",
    "                                               param2,\n",
    "                                               param3, \n",
    "                                               \"Dataset\", \n",
    "                                               metric_lgb, \n",
    "                                               metric_bsl\n",
    "                                              ])\n",
    "\n",
    "    for col in df_res.columns:\n",
    "        if col==\"Dataset\":\n",
    "            continue\n",
    "        df_res.loc[:,col] = df_res[col].astype(float)    \n",
    "    for p in [param1, param2, param3]:\n",
    "        print(p, np.sort(df_res[p].unique()).tolist())\n",
    "    dict_res = {}\n",
    "    for dset in [\"train\", \"val\", \"test\"]:\n",
    "        dict_res.update({dset: df_res[df_res.Dataset==dset].rename(columns={metric_bsl: \"{} ({})\".format(metric_bsl,dset), metric_lgb: \"{} ({})\".format(metric_lgb,dset)})})\n",
    "        dict_res.update({dset: dict_res[dset].drop(columns=[\"Dataset\"]).groupby(horizon_cols + [param1, param2, param3]).mean()})\n",
    "\n",
    "    df_best = dict_res[\"val\"].reset_index().sort_values(horizon_cols+[\"{} (val)\".format(metric_lgb)]).drop_duplicates(horizon_cols, keep=\"first\")\n",
    "    df_best = df_best.set_index(horizon_cols + [param1, param2, param3])\n",
    "    df_best = pd.concat([df_best, \n",
    "                         dict_res[\"test\"], \n",
    "                         dict_res[\"train\"]], join=\"inner\", axis=1)\n",
    "    return df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11eee2-eff3-4693-8a66-f091789e5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_path = \"/cluster/work/grlab/clinical/hirid2/research/vent_planning\"\n",
    "\n",
    "horizon_cols = [\"PredictionHorizon_l\", \"PredictionHorizon_r\"]\n",
    "metric_bsl = \"Baseline\"\n",
    "metric_lgb = \"RMS\"\n",
    "\n",
    "param1 = \"Num_leaves\"\n",
    "param2 = \"Num_rounds\"\n",
    "param3 = \"Stopping_rounds\"\n",
    "\n",
    "lst_seed = np.arange(2020,2025)\n",
    "\n",
    "pred_type = \"in-icu\"\n",
    "pred_type = \"emergency\"\n",
    "\n",
    "is_kanonym = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ae9e70-1534-4d40-9dbe-f98e1896a13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_emer = []\n",
    "df_best_icu = []\n",
    "for i in np.arange(1,6):\n",
    "    out_dir = \"res_%%d_rms_new_temporal_%d\"%i\n",
    "    df_best_emer.append(read_results(os.path.join(vent_path, out_dir), \"emergency\", horizon_cols, param1, param2, param3, metric_bsl, metric_lgb, lst_seed))\n",
    "    df_best_icu.append(read_results(os.path.join(vent_path, out_dir), \"in-icu\", horizon_cols, param1, param2, param3, metric_bsl, metric_lgb, lst_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ce03f-7b9e-4e79-8eca-9f3625430470",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for title, df in [(\"In-ICU patient ventilation prediction\", df_best_icu), \n",
    "                  (\"Newly admitted ventilated emergency patients\", df_best_emer)]:\n",
    "    df_melt = []\n",
    "    for k, df_split in enumerate(df):\n",
    "        tmp = df_split.reset_index()\n",
    "        tmp.loc[:,\"Prediction Horizon\"] = [\"[{:.0f},{:.0f}] h\".format(tmp.iloc[i][horizon_cols[0]], tmp.iloc[i][horizon_cols[1]]) for i in range(len(tmp))]\n",
    "        tmp = tmp.melt(id_vars=[\"Prediction Horizon\"],\n",
    "                       value_vars=[\"{} (test)\".format(metric_bsl), \"{} (test)\".format(metric_lgb)])\n",
    "        tmp = tmp.rename(columns={\"variable\": \"Method\", \"value\": \"MAE\"})\n",
    "        tmp = tmp.replace(\"{} (test)\".format(metric_bsl), metric_bsl)\n",
    "        tmp = tmp.replace(\"{} (test)\".format(metric_lgb), metric_lgb)\n",
    "        tmp.loc[:,\"temporal_split\"] = k\n",
    "        df_melt.append(tmp)\n",
    "    df_melt = pd.concat(df_melt).reset_index(drop=True)\n",
    "\n",
    "    plt.figure(figsize=(w*cm,h*0.7*cm))\n",
    "    sns.barplot(x=\"Prediction Horizon\", y=\"MAE\", hue=\"Method\", data=df_melt, zorder=2)\n",
    "    plt.xticks(rotation=30, horizontalalignment=\"right\")\n",
    "    plt.grid(axis='y')\n",
    "    plt.title(title)\n",
    "    plt.savefig(os.path.join(resp_fig_path, \"fig5_subfig%d\"%n))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168476b7-aca5-486c-b4a9-aef6b1051eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_err_weekday = []\n",
    "rug_plot = []\n",
    "\n",
    "rug_plot_sign = []\n",
    "for i in np.arange(1,6):\n",
    "\n",
    "    for j in range(len(df_best_icu[i-1])):\n",
    "        df_err_weekday = []\n",
    "        rug_plot_tmp = []\n",
    "        feat_dir = \"resource_planning_features_rms_new_temporal_%d\"%i\n",
    "        \n",
    "        for seed in np.arange(2020,2025):\n",
    "            out_dir = \"res_%d_rms_new_temporal_%d\"%(seed, i)\n",
    "            \n",
    "            tmp = df_best_icu[i-1].index[j]\n",
    "            try:\n",
    "                res_icu= np.load(os.path.join(vent_path, out_dir, 'res_test_%d_%d_l%d_r%d_s%d.npz'%(tmp[0],tmp[1],tmp[2],tmp[3],tmp[4])))\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            tmp = df_best_emer[i-1].index[j]\n",
    "            try:\n",
    "                res_emer= np.load(os.path.join(vent_path, out_dir, 'res_emer_test_%d_%d_l%d_r%d_s%d.npz'%(tmp[0],tmp[1],tmp[2],tmp[3],tmp[4])))\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            lbl_test = pd.read_hdf(os.path.join(vent_path, feat_dir, \"label_test_%d_%d.h5\"%(tmp[0],tmp[1])))\n",
    "            lbl_test = lbl_test.loc[res_emer['lst_dt']]\n",
    "            \n",
    "            ts_icu = np.stack([res_icu['groundtruth'],res_icu['prediction'], res_icu['prediction_ffill']], axis=1)\n",
    "            ts_icu = pd.DataFrame(ts_icu, columns=['Groundtruth (in-ICU)', 'RMS (in-ICU)', 'Baseline (in-ICU)'])\n",
    "            ts_icu.loc[:,'Datetime'] = res_icu['lst_dt']\n",
    "            ts_emer = np.stack([res_emer['groundtruth'],res_emer['prediction']], axis=1)\n",
    "            ts_emer = pd.DataFrame(ts_emer,columns=['Groundtruth (Emergency)', 'RMS (Emergency)'])\n",
    "            ts_emer.loc[:,'Datetime'] = res_emer['lst_dt']\n",
    "            ts_emer.loc[:,'Baseline (Emergency)'] = res_emer['median_gt_train']\n",
    "\n",
    "            ts_aggr = ts_icu.merge(ts_emer, left_on='Datetime', right_on='Datetime')\n",
    "            ts_aggr = ts_aggr.merge(lbl_test[[\"VentUse_elective_future\", \"VentUse_future\"]], left_on=\"Datetime\", right_index=True)\n",
    "            \n",
    "#             ts_aggr['Groundtruth (all)'] = ts_aggr[\"VentUse_future\"] - ts_aggr['VentUse_elective_future'].fillna(0)\n",
    "#             ts_aggr['RMS (all)'] = ts_aggr['RMS (in-ICU)'] + ts_aggr['RMS (Emergency)']\n",
    "            \n",
    "            ts_aggr['Groundtruth (all)'] = ts_aggr[\"VentUse_future\"]\n",
    "            ts_aggr['RMS (all)'] = ts_aggr['RMS (in-ICU)'] + ts_aggr['RMS (Emergency)'] + ts_aggr['VentUse_elective_future'].fillna(0)\n",
    "            \n",
    "            # ts_aggr['Baseline (all)'] = ts_aggr['Baseline (in-ICU)'] + ts_aggr['Baseline (Emergency)']\n",
    "            ts_aggr['Baseline (all)'] = ts_aggr['Baseline (in-ICU)'] #emer_patient_num\n",
    "\n",
    "            ts_aggr.loc[:,'Weekday'] =  ts_aggr.Datetime.dt.weekday\n",
    "            ts_aggr.loc[:,'Error (RMS %d)'%seed] = np.abs(ts_aggr['Groundtruth (all)'] - np.round(ts_aggr['RMS (all)']))\n",
    "            ts_aggr.loc[:,'Error (Baseline %d)'%seed] = np.abs(ts_aggr['Groundtruth (all)'] - ts_aggr['Baseline (all)'])\n",
    "            \n",
    "            ts_aggr.loc[:,'Error with sign (RMS %d)'%seed] = (np.round(ts_aggr['RMS (all)']) - ts_aggr['Groundtruth (all)'])\n",
    "            ts_aggr.loc[:,'Error with sign (Baseline %d)'%seed] = (ts_aggr['Baseline (all)'] - ts_aggr['Groundtruth (all)'])\n",
    "            \n",
    "            \n",
    "            df_err_weekday.append(ts_aggr[['Weekday', 'Error (RMS %d)'%seed]].groupby('Weekday').mean())\n",
    "            \n",
    "            rug_plot_tmp2 = ts_aggr.copy()\n",
    "            rug_plot_tmp2 = rug_plot_tmp2.rename(columns={'Groundtruth (all)':'Groundtruth (%d)'%seed,\n",
    "                                                          'RMS (all)': 'RMS (%d)'%seed,\n",
    "                                                          'Baseline (all)': 'Baseline (%d)'%seed})\n",
    "            \n",
    "            rug_plot_tmp.append(rug_plot_tmp2[['Datetime','Groundtruth (%d)'%seed, 'RMS (%d)'%seed, 'Baseline (%d)'%seed, 'Error (RMS %d)'%seed,'Error (Baseline %d)'%seed]].set_index('Datetime') )\n",
    "            rug_plot_tmp3 = rug_plot_tmp2.copy()\n",
    "            rug_plot_tmp3.loc[:,\"Prediction Horizon\"] = \"[%d,%d]h\"%(tmp[0], tmp[1])\n",
    "            rug_plot_sign.append(rug_plot_tmp3)\n",
    "        if len(df_err_weekday) == 0:\n",
    "            continue\n",
    "        df_err_weekday = pd.concat(df_err_weekday, axis=1)\n",
    "        df_err_weekday.loc[:, 'MAE (RMS)'] =  df_err_weekday[[col for col in df_err_weekday.columns if 'RMS' in col]].mean(axis=1)\n",
    "        df_err_weekday.loc[:, \"Prediction Horizon\"] = \"[%d,%d]h\"%(tmp[0], tmp[1])\n",
    "        df_err_weekday = df_err_weekday[['Prediction Horizon', 'MAE (RMS)']]\n",
    "        df_err_weekday.loc[:,'Split'] = 'temporal_%d'%i\n",
    "        df_err_weekday = df_err_weekday.reset_index()\n",
    "        all_err_weekday.append(df_err_weekday)\n",
    "        \n",
    "        rug_plot_tmp = pd.concat(rug_plot_tmp, axis=1).reset_index()\n",
    "        rug_plot_tmp.loc[:, 'Absolute Error (RMS)'] =  np.round(rug_plot_tmp[[col for col in rug_plot_tmp.columns if 'Error (RMS' in col]].mean(axis=1))\n",
    "        rug_plot_tmp.loc[:, 'Absolute Error (Baseline)'] =  rug_plot_tmp[[col for col in rug_plot_tmp.columns if 'Error (Baseline' in col]].mean(axis=1)\n",
    "        rug_plot_tmp.loc[:, 'Groundtruth (all)'] =  np.round(rug_plot_tmp[[col for col in rug_plot_tmp.columns if 'Groundtruth (' in col]].mean(axis=1))\n",
    "        rug_plot_tmp.loc[:, 'RMS (all)'] =  rug_plot_tmp[[col for col in rug_plot_tmp.columns if 'RMS (' in col]].mean(axis=1)\n",
    "        rug_plot_tmp.loc[:, 'Baseline (all)'] =  rug_plot_tmp[[col for col in rug_plot_tmp.columns if 'Baseline (' in col]].mean(axis=1)\n",
    "        rug_plot_tmp.loc[:, \"Prediction Horizon\"] = \"[%d,%d]h\"%(tmp[0], tmp[1])\n",
    "        rug_plot_tmp = rug_plot_tmp[['Datetime','Prediction Horizon', 'Groundtruth (all)', 'RMS (all)', 'Baseline (all)', 'Absolute Error (RMS)', 'Absolute Error (Baseline)']]\n",
    "        rug_plot_tmp.loc[:, 'Split'] = 'temporal_%d'%i\n",
    "        \n",
    "        rug_plot.append(rug_plot_tmp)\n",
    "        \n",
    "all_err_weekday = pd.concat(all_err_weekday).reset_index(drop=True)\n",
    "rug_plot = pd.concat(rug_plot).reset_index(drop=True)\n",
    "rug_plot_sign = pd.concat(rug_plot_sign).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45977af9-34f6-4652-af67-099634fb6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icu_bed = pd.read_hdf(\"/cluster/work/grlab/clinical/hirid2/research/vent_planning/resource_planning_features_rms_new_temporal_1_icu_bed/icu_bed_test_8_16.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b0bed-f205-4650-8132-b9d670cab8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in rug_plot_sign.columns:\n",
    "    if 'sign' in col and 'Baseline' in col:\n",
    "        rug_plot_sign.loc[:,col] = np.sign(rug_plot_sign[col]).astype(float).replace(1,'Over-estimate').replace(-1,'Under-estimate').replace(0,'Correct estimate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4f0c2-1767-4832-b42c-8ada22531f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in rug_plot_sign.columns:\n",
    "    if 'sign' in col and 'Baseline' in col:\n",
    "        plt.figure(figsize=(w*cm, h*cm))\n",
    "        sns.countplot(data=rug_plot_sign, x='Prediction Horizon', hue=col, hue_order=[\"Under-estimate\", \"Over-estimate\", \"Correct estimate\"])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(resp_fig_path, 'estimation_status'))\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad4071-b9bb-41b4-b44d-0e1d72c9aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_summary = []\n",
    "for i in np.arange(1,6):\n",
    "    rug_plot_tmp = rug_plot[rug_plot.Split=='temporal_%d'%i].copy()\n",
    "    \n",
    "    for j in range(len(df_best_icu[i-1])):\n",
    "        if j==3:\n",
    "            plt.figure(figsize=(w*1.5*cm, h*cm))\n",
    "        tmp = df_best_icu[i-1].index[j]\n",
    "        rug_plot_tmp2 = rug_plot_tmp[rug_plot_tmp[\"Prediction Horizon\"]==\"[%d,%d]h\"%(tmp[0], tmp[1])].copy()\n",
    "        rug_plot_tmp2.loc[:,'Diff'] = rug_plot_tmp2['Absolute Error (RMS)'] - rug_plot_tmp2['Absolute Error (Baseline)'] \n",
    "        if j==3:\n",
    "            plt.plot(rug_plot_tmp2.Datetime, rug_plot_tmp2['Groundtruth (all)'], color='C7')\n",
    "            plt.plot(rug_plot_tmp2.Datetime, rug_plot_tmp2['RMS (all)'], color='C6')\n",
    "            plt.plot(rug_plot_tmp2.Datetime, rug_plot_tmp2['Baseline (all)'], color='C8')\n",
    "            \n",
    "        # sns.rugplot(data=rug_plot_tmp2, x= 'Datetime' , hue='Model Comparison', hue_order=['rms predicts better', 'Baseline predicts better'],expand_margins=False)\n",
    "        for delta in range(0,4):\n",
    "            rug_plot_tmp2.loc[:,'Model Comparison'] = rug_plot_tmp2.Diff.apply(lambda x: 'rms predicts better' if x<-delta else ('Baseline predicts better' if x>delta else 'equally better'))\n",
    "            cnt_model_comp =rug_plot_tmp2['Model Comparison'].value_counts()\n",
    "            if 'Baseline predicts better' not in cnt_model_comp.index:\n",
    "                cnt_model_comp.loc['Baseline predicts better'] = 0\n",
    "            if j==3:\n",
    "                plt.vlines(rug_plot_tmp2.Datetime[rug_plot_tmp2['Model Comparison']=='rms predicts better'], ymax=-3*(delta-1+1), ymin=-3*(delta+1)+0.1, color='C0', linewidth=8.5)\n",
    "                plt.vlines(rug_plot_tmp2.Datetime[rug_plot_tmp2['Model Comparison']=='Baseline predicts better'], ymax=-3*(delta-1+1), ymin=-3*(delta+1)+0.1, color='C1', linewidth=8.5)\n",
    "                delta_summary.append([delta+1, i, cnt_model_comp.loc['rms predicts better']/len(rug_plot_tmp2)*100,cnt_model_comp.loc['Baseline predicts better']/len(rug_plot_tmp2)*100])\n",
    "        if j==3:\n",
    "            plt.axhline(0, linewidth=1, color='k')\n",
    "            plt.axhline(-3, linewidth=1, color='k')\n",
    "            plt.axhline(-6, linewidth=1, color='k')\n",
    "            plt.axhline(-9, linewidth=1, color='k')\n",
    "            plt.axhline(-12, linewidth=1, color='k')\n",
    "            ax = plt.gca()\n",
    "\n",
    "            plt.legend(['Groundtruth', 'RMS', 'Baseline', 'RMS predicts at least $\\\\delta$ better', 'Baseline predicts at least $\\\\delta$ better'],\n",
    "                        bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left',\n",
    "                      ncols=2, mode=\"expand\", borderaxespad=0.)            \n",
    "            x_span = [np.datetime64('2018-11-01'),np.datetime64('2018-11-02')]\n",
    "            y_span = rug_plot_tmp2[(rug_plot_tmp2['Datetime']<=x_span[1])&(rug_plot_tmp2['Datetime']>=x_span[0])][['Groundtruth (all)', 'RMS (all)', 'Baseline (all)']].max(axis=1).max()\n",
    "            plt.xlim(x_span)\n",
    "            plt.ylim([-12.3,y_span])\n",
    "            plt.yticks(np.concatenate([[-12,-9,-6,-3], np.arange(0,y_span+5,5)]),\n",
    "                       ['$\\\\delta=%d$'%y for y in range(1,5)[::-1]]+['%d'%y for y in np.arange(0,y_span+5,5)])\n",
    "            ax.spines[['bottom']].set_visible(False)\n",
    "            xtickslabel = np.datetime64('2018-11-01')+np.array([np.timedelta64(i,'h') for i in np.arange(0,24)])\n",
    "            plt.xticks(xtickslabel, [\"%0d:00\"%x for x in np.arange(24)], rotation=45, horizontalalignment=\"right\")\n",
    "            plt.xlabel('2018-11-01')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(resp_fig_path, \"fig5_subfig9\"))\n",
    "            plt.show()\n",
    "\n",
    "delta_summary = pd.DataFrame(delta_summary, columns=['delta', 'temporal_split', 'RMS Better', 'Baseline Better'])\n",
    "delta_summary = delta_summary.groupby('delta').mean().iloc[:,1:].reset_index()\n",
    "delta_summary.loc[:,'RMS Better'] = delta_summary['RMS Better'].apply(lambda x: '%1.1f%%'%x)\n",
    "delta_summary.loc[:,'Baseline Better'] = delta_summary['Baseline Better'].apply(lambda x: '%1.1f%%'%x)\n",
    "delta_summary.loc[:,'delta'] = delta_summary['delta'].apply(lambda x: '$\\delta=%d$'%x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12251a93-19ad-42a5-9f65-e6f6ad92a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(w*0.75*cm, h*cm))\n",
    "the_table = plt.table(cellText=delta_summary.iloc[:,1:].values,\n",
    "                      rowLabels=delta_summary['delta'].values,\n",
    "                      colLabels=delta_summary.columns[1:].values,\n",
    "                      loc='center')\n",
    "ax = plt.gca()\n",
    "ax.spines[['left','bottom']].set_visible(False)\n",
    "the_table.auto_set_font_size(False)\n",
    "the_table.set_fontsize(6)\n",
    "plt.xticks([],[])\n",
    "plt.yticks([],[])\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(resp_fig_path, \"fig5_subfig10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a90c4-20cb-4cd2-886d-f3104bf8cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(\"=====\")    \n",
    "    display(df_best_icu[i])\n",
    "    display(df_best_emer[i])\n",
    "    print(\"=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25defa4-e5ad-4193-81fa-4b30e4e3f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_day_aggr = []\n",
    "for i in np.arange(1,6):\n",
    "    rug_plot_tmp = rug_plot[rug_plot.Split==\"temporal_%d\"%i].copy()\n",
    "    for j in range(len(df_best_icu[i-1])):\n",
    "        tmp = df_best_icu[i-1].index[j]\n",
    "        rug_plot_tmp2 = rug_plot_tmp[rug_plot_tmp[\"Prediction Horizon\"]==\"[%d,%d]h\"%(tmp[0], tmp[1])].copy()\n",
    "        rug_plot_tmp2.loc[:,'Hour'] = rug_plot_tmp2.Datetime.dt.hour\n",
    "        err_day = rug_plot_tmp2[['Hour', 'Absolute Error (RMS)', 'Absolute Error (Baseline)']].groupby('Hour').mean().reset_index()\n",
    "        err_day.loc[:,\"Prediction Horizon\"] = \"[%d,%d]h\"%(tmp[0], tmp[1])\n",
    "        err_day.loc[:,\"Split\"] = \"temporal_%d\"%i\n",
    "        err_day_aggr.append(err_day)\n",
    "        \n",
    "err_day = pd.concat(err_day_aggr).reset_index(drop=True)\n",
    "for j in range(len(df_best_icu[i-1])):\n",
    "    tmp = df_best_icu[i-1].index[j]\n",
    "    err_day_tmp = err_day[err_day[\"Prediction Horizon\"]==\"[%d,%d]h\"%(tmp[0], tmp[1])].copy()\n",
    "    \n",
    "    err_day_mean = err_day_tmp[['Hour', 'Absolute Error (RMS)', 'Absolute Error (Baseline)']].groupby(\"Hour\").mean()\n",
    "    err_day_std = err_day_tmp[['Hour', 'Absolute Error (RMS)', 'Absolute Error (Baseline)']].groupby(\"Hour\").std()\n",
    "\n",
    "    plt.figure(figsize=(w*cm,h*cm))\n",
    "    plt.plot(err_day_mean.index, err_day_mean[\"Absolute Error (RMS)\"], label='RMS', marker='.', color='C0')\n",
    "    plt.plot(err_day_mean.index, err_day_mean[\"Absolute Error (Baseline)\"], label='Baseline', marker='.', color='C1')\n",
    "    # plt.title(err_day_tmp.iloc[0][\"Prediction Horizon\"])\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('Prediction Horizon')\n",
    "    xtickslabel = []\n",
    "    for k in np.arange(0,24,4):\n",
    "        if k+tmp[0] >= 24:\n",
    "            xtickslabel.append(\"%02d:00$_{(+1~\\\\mathrm{day})}$-%02d:00$_{(+1~\\\\mathrm{day})}$\"%((k+tmp[0])%24, (k+tmp[1])%24))\n",
    "        elif k+tmp[1] >=24:\n",
    "            xtickslabel.append(\"%02d:00-%02d:00$_{(+1~\\\\mathrm{day})}$\"%(k+tmp[0], (k+tmp[1])%24))\n",
    "        else:\n",
    "            xtickslabel.append(\"%02d:00-%02d:00\"%(k+tmp[0], k+tmp[1]))\n",
    "    plt.xticks(np.arange(0,24,4), xtickslabel, rotation=90, horizontalalignment=\"center\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(resp_fig_path, 'fig5_subfig2%d'%j))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75c4d0-613b-44cd-8db5-71c3167db97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1,6):\n",
    "    rug_plot_tmp = rug_plot[rug_plot.Split=='temporal_%d'%i].copy()\n",
    "    for j in range(len(df_best_icu[i-1])):\n",
    "        tmp = df_best_icu[i-1].index[j]\n",
    "        rug_plot_tmp2 = rug_plot_tmp[rug_plot_tmp[\"Prediction Horizon\"]==\"[%d,%d]h\"%(tmp[0], tmp[1])].copy()\n",
    "        lbl_test = pd.read_hdf(os.path.join(vent_path, feat_dir, \"label_test_%d_%d.h5\"%(tmp[0],tmp[1])))\n",
    "        lbl_test = lbl_test.loc[res_emer['lst_dt']]\n",
    "        rug_plot_tmp2 = rug_plot_tmp2.merge(lbl_test[['VentUse']], right_index=True, left_on='Datetime')\n",
    "        rug_plot_tmp2.loc[:,'Date'] = rug_plot_tmp2.Datetime.dt.date\n",
    "        plt.figure(figsize=(w*cm, h*0.75*cm))\n",
    "        date_summary = rug_plot_tmp2[['Date', 'VentUse']].groupby('Date').max()\n",
    "        plt.hist(date_summary['VentUse'], bins=range(int(date_summary['VentUse'].max())+1), density=True, color='C7')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.xlabel('# ventilators in Use (Daily)')\n",
    "        # plt.title(\"[%d,%d]h\"%(tmp[0], tmp[1]))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(resp_fig_path, \"fig5_subfig11\"))\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da90444e-fb76-4f16-8868-df3d5fd28d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in [\"train\", \"val\", \"test\"]:\n",
    "    lbl_test = pd.read_hdf(os.path.join(vent_path, feat_dir, \"label_%s_%d_%d.h5\"%(dset, tmp[0],tmp[1])))\n",
    "    print(lbl_test.index[0], lbl_test.index[-1])\n",
    "    print(lbl_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cad5c4-5389-4316-9e65-3fe588272dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_weekday = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "all_err_weekday.loc[:,'Weekday'] = all_err_weekday['Weekday'].apply(lambda x: lst_weekday[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9194b1-b979-48f2-9ef9-5c226b0f74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(w*2*cm, h*0.75*cm))\n",
    "sns.barplot(y='MAE (RMS)', x='Prediction Horizon', hue='Weekday', data=all_err_weekday)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(resp_fig_path, \"fig5_subfig2\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a3493-6b84-4bab-8ff4-7f45f7807337",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_mae = rug_plot[['Prediction Horizon', 'Split', 'Absolute Error (RMS)', 'Absolute Error (Baseline)']].groupby(['Prediction Horizon', 'Split']).mean().reset_index()\n",
    "overall_mae = overall_mae[['Prediction Horizon', 'Absolute Error (RMS)', 'Absolute Error (Baseline)']].groupby('Prediction Horizon').mean()\n",
    "overall_mae = overall_mae.reset_index().melt(id_vars='Prediction Horizon', var_name='Method', value_name='MAE')\n",
    "overall_mae.loc[:,'Method'] = overall_mae['Method'].replace({'Absolute Error (RMS)':'RMS','Absolute Error (Baseline)':'Baseline'})\n",
    "plt.figure(figsize=(w*cm,h*0.7*cm))\n",
    "sns.barplot(x=\"Prediction Horizon\", y=\"MAE\", hue=\"Method\", data=overall_mae, zorder=2, \n",
    "            order=['[4,8]h', '[4,12]h', '[8,12]h', '[8,16]h', '[16,24]h'])\n",
    "plt.xticks(range(5), ['4-8h', '4-12h', '8-12h', '8-16h', '16-24h'], rotation=30, horizontalalignment=\"right\")\n",
    "plt.grid(axis='y')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left',\n",
    "                      ncols=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig(os.path.join(resp_fig_path, \"fig5_subfig12\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c05ac6-fbb1-4b7c-835b-51338da10914",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1,6):\n",
    "    rug_plot_tmp = rug_plot[rug_plot.Split=='temporal_%d'%i].copy()\n",
    "    \n",
    "    for j in range(len(df_best_icu[i-1]))[-1:]:\n",
    "        print('temporal_%d'%i)\n",
    "        if i==5:\n",
    "            plt.figure(figsize=(w*1.5*cm, h*cm))\n",
    "        tmp = df_best_icu[i-1].index[j]\n",
    "        rug_plot_tmp2 = rug_plot_tmp[rug_plot_tmp[\"Prediction Horizon\"]==\"[%d,%d]h\"%(tmp[0], tmp[1])].copy()\n",
    "        rug_plot_tmp2.loc[:,'Diff'] = rug_plot_tmp2['Absolute Error (RMS)'] - rug_plot_tmp2['Absolute Error (Baseline)'] \n",
    "        if i==5:\n",
    "            plt.plot(rug_plot_tmp2.Datetime, rug_plot_tmp2['Groundtruth (all)'], color='C7')\n",
    "            plt.plot(rug_plot_tmp2.Datetime, rug_plot_tmp2['RMS (all)'], color='C6')\n",
    "            plt.plot(rug_plot_tmp2.Datetime, rug_plot_tmp2['Baseline (all)'], color='C8')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb446f57-c423-4cdc-8711-675c0da6e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1,6):\n",
    "    rug_plot_tmp = rug_plot[rug_plot.Split=='temporal_%d'%i].copy()\n",
    "    \n",
    "    for j in range(len(df_best_icu[i-1]))[-1:]:\n",
    "        print('temporal_%d'%i)\n",
    "        if i==5:\n",
    "            plt.figure(figsize=(w*2.75*cm, h*0.6*cm))\n",
    "        tmp = df_best_icu[i-1].index[j]\n",
    "        rug_plot_tmp2 = rug_plot_tmp[rug_plot_tmp[\"Prediction Horizon\"]==\"[%d,%d]h\"%(tmp[0], tmp[1])].copy()\n",
    "        rug_plot_tmp2.loc[:,'Diff'] = rug_plot_tmp2['Absolute Error (RMS)'] - rug_plot_tmp2['Absolute Error (Baseline)'] \n",
    "        if i==5:\n",
    "            plt.yticks([],[])\n",
    "            ax=plt.gca()\n",
    "            ax.spines[\"left\"].set_visible(False)\n",
    "            ax = plt.gca().twinx()\n",
    "            plt.plot(rug_plot_tmp2.Datetime, rug_plot_tmp2['Groundtruth (all)'], color='C7', linestyle=\":\", label=\"Actual number of mechanically ventilated patients in [8,16]h\")\n",
    "            plt.plot(rug_plot_tmp2.Datetime, rug_plot_tmp2['RMS (all)'], color='C6', label=\"Estimated number of mechanically ventilated patients in [8,16]h\")\n",
    "            ax.spines[\"left\"].set_visible(False)\n",
    "            ax.spines[\"right\"].set_visible(True)\n",
    "            ax.spines['right'].set_color('C6')\n",
    "            ax = plt.gca()\n",
    "            ax.tick_params(axis='y', colors='C6')  \n",
    "            ax.yaxis.label.set_color('C6')\n",
    "            plt.yticks()\n",
    "            plt.xticks([],[])\n",
    "            plt.xlim([np.datetime64(\"2019-01-01\"),np.datetime64(\"2019-03-31\")])\n",
    "            plt.ylabel(\"Number of\\nVentilated Patients\")\n",
    "            plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=1, mode=\"expand\", borderaxespad=0.)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\"paper_figures_resp/esti_vent_long\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad04a1-5110-4d29-901b-6a88f2365cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1,6):\n",
    "    rug_plot_tmp = rug_plot[rug_plot.Split==\"temporal_%d\"%i].copy()\n",
    "    for j in range(len(df_best_icu[i-1])):\n",
    "        tmp = df_best_icu[i-1].index[j]\n",
    "        rug_plot_tmp2 = rug_plot_tmp[rug_plot_tmp[\"Prediction Horizon\"]==\"[%d,%d]h\"%(tmp[0], tmp[1])].copy()\n",
    "        lbl_test = pd.read_hdf(os.path.join(vent_path, feat_dir, \"label_test_%d_%d.h5\"%(tmp[0],tmp[1])))\n",
    "        lbl_test = lbl_test.loc[res_emer['lst_dt']]\n",
    "        rug_plot_tmp2 = rug_plot_tmp2.merge(lbl_test[['VentUse']], right_index=True, left_on='Datetime')\n",
    "\n",
    "        plt.figure(figsize=(w*cm, h*0.75*cm))\n",
    "        err_hist = []\n",
    "        cnt = []\n",
    "        xvals = np.arange(rug_plot_tmp2['VentUse'].min(),rug_plot_tmp2['VentUse'].max(),4)\n",
    "        for k in xvals:\n",
    "            rug_plot_tmp3 = rug_plot_tmp2[(rug_plot_tmp2['VentUse']>=k)&(rug_plot_tmp2['VentUse']<k+4)]\n",
    "            cnt.append(len(rug_plot_tmp3))\n",
    "            err_rms_tmp = rug_plot_tmp3['Absolute Error (RMS)'].mean()\n",
    "            err_hist.append(err_rms_tmp)\n",
    "        plt.bar(np.arange(len(err_hist))-0.3+0.1, err_hist, width=0.4, alpha=1, label='RMS', color='C0')\n",
    "        err_hist = []\n",
    "        for k in xvals:\n",
    "            rug_plot_tmp3 = rug_plot_tmp2[(rug_plot_tmp2['VentUse']>=k)&(rug_plot_tmp2['VentUse']<k+4)]\n",
    "            err_rms_tmp = rug_plot_tmp3['Absolute Error (Baseline)'].mean()\n",
    "            err_hist.append(err_rms_tmp)\n",
    "        plt.bar(np.arange(len(err_hist))+0.2, err_hist, width=0.4, alpha=1, label='Baseline', color='C1')\n",
    "        plt.xticks(range(len(err_hist)), \n",
    "                  [\"%d-%d\\n(n=%d)\"%(xvals[i],xvals[i]+4-1, cnt[i]) for i in range(len(xvals))], rotation=30, horizontalalignment='right')\n",
    "        \n",
    "        plt.ylabel(\"MAE of Ventilation\\nPrediction in %d-%dh\"%(tmp[0], tmp[1]))\n",
    "        plt.xlabel(\"# Ventilators in Use (Hourly)\")\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left',\n",
    "                      ncols=2, mode=\"expand\", borderaxespad=0.)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(resp_fig_path, \"fig5_subfig3%d\"%j))\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a553d-d1f7-4a9f-8bfe-ddee058b47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"Prediction_vent\", \"Prediction_extu\", \"Prediction_fail\", \"Prediction_exfa\", \"VentUse\", \"weekday\", \"total_vent_use\", \"total_patient\", \"idx_wind\"]\n",
    "elective_pids = pd.read_hdf(\"/cluster/work/grlab/clinical/hirid2/research/1a_hdf5_clean/v8/static.h5\")[[\"PatientID\", \"Emergency\"]]\n",
    "elective_pids = np.sort(elective_pids[elective_pids.Emergency==0].PatientID.unique())\n",
    "\n",
    "lst_features = np.concatenate([ [\"min_%s\"%col for col in feature_cols[:4]], \n",
    "                                [\"p25_%s\"%col for col in feature_cols[:4]],\n",
    "                                [\"median_%s\"%col for col in feature_cols[:4]],\n",
    "                                [\"p75_%s\"%col for col in feature_cols[:4]],\n",
    "                                [\"max_%s\"%col for col in feature_cols[:4]],\n",
    "                                [\"current_%s\"%col for col in feature_cols[:4]],\n",
    "                                [\"vent_last_hour\", \"vent_since_admission\"],\n",
    "                                [\"min_total_vent\", \"max_total_vent\"],\n",
    "                                [\"min_total_patient\", \"max_total_patient\"],\n",
    "                                [\"weekday\", \"hourOftheDay\",\"timeSinceAdmission\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec295c9-c447-42ad-bef4-d45b306ec115",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_features  = np.concatenate((lst_features, [\"curr_vent_state\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a1326-c8a6-4485-9a9c-737029ea78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(lst_features.reshape((-1,1)),columns=[\"Feature\"]).to_csv(\"resource_planning_feature.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
